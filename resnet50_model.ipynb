{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Filename: resnet50_model.ipynb\n",
    "Description: MRI brain images classification analysis with ResNet50 model\n",
    "\n",
    "Author: Ng, Wee Ding\n",
    "Date Created: 2024-11-30\n",
    "Last Modified: 2024-12-06\n",
    "Version: 1.0\n",
    "\n",
    "License: MIT\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from datetime import datetime \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, knn_graph\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def save_model(epochs, model, optimizer, criterion, modelname=\"default\"):\n",
    "    \"\"\"\n",
    "    Function to save the trained model to disk.\n",
    "    \"\"\"\n",
    "    torch.save({\n",
    "                'epoch': epochs,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': criterion,\n",
    "                }, f\"./output/model-{modelname}-{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}.pth\"\n",
    "               )\n",
    "\n",
    "\n",
    "# Dataset Class\n",
    "class BrainTumorDataset:\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "def train_model(model, dataloaders, device, num_epochs=10, modelname=\"default\"):\n",
    "    criterion = nn.CrossEntropyLoss()  # Multi-class classification loss\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Metrics storage\n",
    "    train_metrics = {'loss': [], 'precision': [], 'recall': [], 'f1': [], 'accuracy': []}\n",
    "    val_metrics = {'precision': [], 'recall': [], 'f1': [], 'accuracy': []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        train_labels, train_preds = [], []\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for images, labels in dataloaders['train']:\n",
    "            images, labels = images.to(device), labels.to(device).long()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)  # Outputs logits\n",
    "            loss = criterion(outputs, labels)  # Labels must be integer-encoded\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # Predictions\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            train_preds.extend(preds)\n",
    "            train_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        # Compute training metrics\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            train_labels, train_preds, average='macro', zero_division=1\n",
    "        )\n",
    "        accuracy = accuracy_score(train_labels, train_preds)\n",
    "        train_metrics['loss'].append(epoch_loss / len(dataloaders['train']))\n",
    "        train_metrics['precision'].append(precision)\n",
    "        train_metrics['recall'].append(recall)\n",
    "        train_metrics['f1'].append(f1)\n",
    "        train_metrics['accuracy'].append(accuracy)\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        val_labels, val_preds = [], []\n",
    "        val_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in dataloaders['val']:\n",
    "                images, labels = images.to(device), labels.to(device).long()\n",
    "                outputs = model(images)\n",
    "                val_loss += criterion(outputs, labels).item()\n",
    "                preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "                val_preds.extend(preds)\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        # Compute validation metrics\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            val_labels, val_preds, average='macro', zero_division=1\n",
    "        )\n",
    "        accuracy = accuracy_score(val_labels, val_preds)\n",
    "        val_metrics['precision'].append(precision)\n",
    "        val_metrics['recall'].append(recall)\n",
    "        val_metrics['f1'].append(f1)\n",
    "        val_metrics['accuracy'].append(accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, \"\n",
    "              f\"Train Acc: {train_metrics['accuracy'][-1]:.4f}, Val Acc: {val_metrics['accuracy'][-1]:.4f}\")\n",
    "\n",
    "    save_model(num_epochs, model, optimizer, criterion, modelname)\n",
    "    return model, train_metrics, val_metrics, num_epochs\n",
    "\n",
    "\n",
    "def show_metrics(model, train_metrics, val_metrics, num_epochs=10, modelname=\"default\"):\n",
    "    # Print final metrics\n",
    "    print(\"\\nFinal Metrics After All Epochs:\")\n",
    "    print(\"Training Metrics:\")\n",
    "    for metric, values in train_metrics.items():\n",
    "        print(f\"{metric.capitalize()}: {values[-1]:.4f}\")\n",
    "    print(\"\\nValidation Metrics:\")\n",
    "    for metric, values in val_metrics.items():\n",
    "        print(f\"{metric.capitalize()}: {values[-1]:.4f}\")\n",
    "\n",
    "    # Define different line styles for each metric\n",
    "    line_styles = {\n",
    "        'loss':'-',\n",
    "        'precision': '-',\n",
    "        'recall': '--',\n",
    "        'f1': '-.',\n",
    "        'accuracy': ':'\n",
    "    }\n",
    "    # Combined Plot of Metrics\n",
    "    epochs = range(1, num_epochs + 1)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for metric in ['loss']:\n",
    "        plt.plot(epochs, train_metrics[metric], label=f'Train {metric.capitalize()}', color='black', linestyle=line_styles[metric])\n",
    "    for metric in ['precision', 'recall', 'f1', 'accuracy']:\n",
    "        plt.plot(epochs, train_metrics[metric], label=f'Train {metric.capitalize()}', color='blue', linestyle=line_styles[metric])\n",
    "    for metric in ['precision', 'recall', 'f1', 'accuracy']:\n",
    "        plt.plot(epochs, val_metrics[metric], label=f'Val {metric.capitalize()}', color='red', linestyle=line_styles[metric])\n",
    "\n",
    "    plt.title(f'Metrics over Epochs - CNN ResNet50')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('score')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f\"./output/metric-{modelname}-{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}.png\")\n",
    "    plt.show()\n",
    "    print(f\"Validation Accuracy: {val_metrics['accuracy'][-1]:.4f}\")\n",
    "    print(f\"Training Accuracy: {train_metrics['accuracy'][-1]:.4f}\")\n",
    "\n",
    "def evaluate_model(model, dataloader, device, return_images=False):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    all_probs = []\n",
    "    all_images = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for D in dataloader:\n",
    "            images, labels = D\n",
    "            images = images.to(device)  # Move images to the device\n",
    "            labels = labels.to(device)  # Move labels to the device\n",
    "            #images = images.permute(0, 3, 1, 2)  # Change channel order\n",
    "\n",
    "            y_hat = model(images)  # Get model predictions\n",
    "            y_hat_probs = torch.softmax(y_hat, dim=1)  # Apply softmax for probabilities\n",
    "            \n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            all_predictions.append(torch.argmax(y_hat_probs, dim=1).cpu().numpy())  # Get predicted classes\n",
    "            all_probs.append(y_hat_probs.cpu().numpy())  # Store probabilities\n",
    "            if return_images:\n",
    "                all_images.append(images.cpu())  # Store images for visualization\n",
    "\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    all_predictions = np.concatenate(all_predictions)\n",
    "    all_probs = np.concatenate(all_probs)\n",
    "\n",
    "    if return_images:\n",
    "        all_images = torch.cat(all_images)  # Combine images into a single tensor\n",
    "        return all_labels, all_predictions, all_probs, all_images\n",
    "    return all_labels, all_predictions, all_probs\n",
    "\n",
    "def plot_results(true_labels, predicted_labels, predicted_probs, class_names):\n",
    "    \"\"\"\n",
    "    Plots the confusion matrix and calculates accuracy, ROC-AUC, and other metrics.\n",
    "    Displays class names instead of digits in the confusion matrix.\n",
    "    \n",
    "    Args:\n",
    "        true_labels: Ground truth labels, as integers.\n",
    "        predicted_labels: Model-predicted labels, as integers.\n",
    "        predicted_probs: Predicted probabilities for each class.\n",
    "        class_names: List of class names corresponding to the class indices.\n",
    "    \"\"\"\n",
    "    # Ensure true_labels are scalar integers\n",
    "    true_labels_scalar = np.array(true_labels, dtype=int)  # Assume true_labels are already integer-encoded\n",
    "\n",
    "    # Calculate and print accuracy\n",
    "    accuracy = accuracy_score(true_labels_scalar, predicted_labels)\n",
    "    print(f'Validation: {accuracy:.4f}')\n",
    "\n",
    "    # Compute confusion matrix and print classification report\n",
    "    cm = confusion_matrix(true_labels_scalar, predicted_labels)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(true_labels_scalar, predicted_labels, target_names=class_names))\n",
    "\n",
    "\n",
    "    # Plot confusion matrix with class names\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix - CNN ResNet50')\n",
    "    plt.show()\n",
    "    print(f'Validation Accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    # Convert true_labels to one-hot format for ROC-AUC calculations\n",
    "    n_classes = len(class_names)\n",
    "    true_labels_one_hot = np.zeros((len(true_labels_scalar), n_classes))\n",
    "    for idx, label in enumerate(true_labels_scalar):\n",
    "        true_labels_one_hot[idx, label] = 1\n",
    "\n",
    "    # Calculate ROC-AUC for each class\n",
    "    roc_auc_scores = []\n",
    "    for i in range(n_classes):\n",
    "        roc_auc = roc_auc_score(true_labels_one_hot[:, i], predicted_probs[:, i])\n",
    "        roc_auc_scores.append(roc_auc)\n",
    "\n",
    "\n",
    "\n",
    "    # Plot ROC-AUC curves\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for i in range(n_classes):\n",
    "        fpr, tpr, _ = roc_curve(true_labels_one_hot[:, i], predicted_probs[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "    plt.title(\"ROC Curves - CNN ResNet50\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    print(f'Validation Accuracy: {accuracy:.4f}')\n",
    "    print(\"ROC-AUC Scores for each class:\")\n",
    "    output = \", \".join([f\"{class_name}: {roc_auc_scores[i]:.4f}\" for i, class_name in enumerate(class_names)])\n",
    "    print(output)\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        print(f\"{class_name}: {roc_auc_scores[i]:.4f}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_misclassified_images(images, true_labels, predicted_labels, n_rows=2, n_cols=5):\n",
    "    \"\"\"\n",
    "    Plots up to 10 randomly selected misclassified images in a grid (2 rows, 5 columns).\n",
    "\n",
    "    Args:\n",
    "        images: Tensor of images.\n",
    "        true_labels: Ground truth labels (scalar or one-hot encoded).\n",
    "        predicted_labels: Predicted labels (scalar).\n",
    "        n_rows: Number of rows in the grid.\n",
    "        n_cols: Number of columns in the grid.\n",
    "    \"\"\"\n",
    "    # Ensure true_labels are scalar\n",
    "    if len(true_labels.shape) > 1:  # If one-hot encoded\n",
    "        true_labels_scalar = np.argmax(true_labels, axis=1)\n",
    "    else:  # Already scalar\n",
    "        true_labels_scalar = true_labels\n",
    "\n",
    "    # Find misclassified indices\n",
    "    misclassified_indices = np.where(true_labels_scalar != predicted_labels)[0]\n",
    "\n",
    "    # Select up to 10 random misclassified indices\n",
    "    selected_indices = random.sample(list(misclassified_indices), min(len(misclassified_indices), n_rows * n_cols))\n",
    "\n",
    "    plt.figure(figsize=(10, n_rows * 2))\n",
    "    plt.suptitle(\"Misclassified Images - CNN ResNet50\")\n",
    "    for i, index in enumerate(selected_indices):\n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "        plt.imshow(images[index].permute(1, 2, 0).cpu().numpy())  # Convert image tensor for visualization\n",
    "        plt.title(f'True: {true_labels_scalar[index]}\\nPred: {predicted_labels[index]}', fontsize=12)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_correctly_predicted_images(images, true_labels, predicted_labels, n_rows=2, n_cols=5):\n",
    "    \"\"\"\n",
    "    Plots up to 10 randomly selected correctly predicted images in a grid (2 rows, 5 columns).\n",
    "\n",
    "    Args:\n",
    "        images: Tensor of images.\n",
    "        true_labels: Ground truth labels (scalar or one-hot encoded).\n",
    "        predicted_labels: Predicted labels (scalar).\n",
    "        n_rows: Number of rows in the grid.\n",
    "        n_cols: Number of columns in the grid.\n",
    "    \"\"\"\n",
    "    # Ensure true_labels are scalar\n",
    "    if len(true_labels.shape) > 1:  # If one-hot encoded\n",
    "        true_labels_scalar = np.argmax(true_labels, axis=1)\n",
    "    else:  # Already scalar\n",
    "        true_labels_scalar = true_labels\n",
    "\n",
    "    # Find correctly predicted indices\n",
    "    correct_indices = np.where(true_labels_scalar == predicted_labels)[0]\n",
    "\n",
    "    # Select up to 10 random correctly predicted indices\n",
    "    selected_indices = random.sample(list(correct_indices), min(len(correct_indices), n_rows * n_cols))\n",
    "\n",
    "    plt.figure(figsize=(10, n_rows * 2))\n",
    "    plt.suptitle(\"Correctly Classified Images - CNN ResNet50\")\n",
    "    for i, index in enumerate(selected_indices):\n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "        plt.imshow(images[index].permute(1, 2, 0).cpu().numpy())  # Convert image tensor for visualization\n",
    "        plt.title(f'True: {true_labels_scalar[index]}\\nPred: {predicted_labels[index]}', fontsize=12)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "print(\"Loaded utilities libraries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet Model\n",
    "class ResNetMultiLabel(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(ResNetMultiLabel, self).__init__()\n",
    "        # Load pre-trained ResNet\n",
    "        self.base_model = models.resnet50(pretrained=True)\n",
    "        # Replace the fully connected layer\n",
    "        num_ftrs = self.base_model.fc.in_features\n",
    "        self.base_model.fc = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, num_classes),\n",
    "            nn.Sigmoid()  # For multi-label output\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "\n",
    "class ResNetMultiClass(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(ResNetMultiClass, self).__init__()\n",
    "        # Load pre-trained ResNet\n",
    "        self.base_model = models.resnet50(pretrained=True)\n",
    "        # Replace the fully connected layer\n",
    "        num_ftrs = self.base_model.fc.in_features\n",
    "        self.base_model.fc = nn.Linear(num_ftrs, num_classes)  # No sigmoid here\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)  # Outputs logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data_dir = \"test_data\"\n",
    "    train_dir = os.path.join(data_dir, \"Training\")\n",
    "    val_dir = os.path.join(data_dir, \"Testing\")\n",
    "    \n",
    "    # Define class labels\n",
    "    classes = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
    "    class_names = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
    "    train_paths = []\n",
    "    train_labels = []\n",
    "    val_paths = []\n",
    "    val_labels = []\n",
    "\n",
    "    # Prepare training data\n",
    "    for idx, cls in enumerate(classes):\n",
    "        class_dir = os.path.join(train_dir, cls)\n",
    "        for img_path in os.listdir(class_dir):\n",
    "            train_paths.append(os.path.join(class_dir, img_path))\n",
    "            train_labels.append(idx)  # Integer label (multi-class)\n",
    "\n",
    "    # Prepare validation data\n",
    "    for idx, cls in enumerate(classes):\n",
    "        class_dir = os.path.join(val_dir, cls)\n",
    "        for img_path in os.listdir(class_dir):\n",
    "            val_paths.append(os.path.join(class_dir, img_path))\n",
    "            val_labels.append(idx)  # Integer label (multi-class)\n",
    "\n",
    "    # Data transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    # Create datasets and loaders\n",
    "    train_dataset = BrainTumorDataset(train_paths, train_labels, transform=transform)\n",
    "    val_dataset = BrainTumorDataset(val_paths, val_labels, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "    dataloaders = {'train': train_loader, 'val': val_loader}\n",
    "\n",
    "    # Define model and device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model_resnet50 = ResNetMultiClass(num_classes=len(classes)).to(device)\n",
    "\n",
    "    # Train the model\n",
    "    model, train_metrics, val_metrics, num_epochs = train_model(model_resnet50, dataloaders, device, 10, \"resnet50\")\n",
    "\n",
    "    # Print final metrics\n",
    "    print(\"\\nTraining Completed!\")\n",
    "    print(\"Train Metrics (Final Epoch):\")\n",
    "    for metric, values in train_metrics.items():\n",
    "        print(f\"{metric.capitalize()}: {values[-1]:.4f}\")\n",
    "\n",
    "    print(\"\\nValidation Metrics (Final Epoch):\")\n",
    "    for metric, values in val_metrics.items():\n",
    "        print(f\"{metric.capitalize()}: {values[-1]:.4f}\")\n",
    "\n",
    "    # Evaluate the model\n",
    "    true_labels, predicted_labels, all_probs = evaluate_model(model, val_loader, device)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(true_labels, predicted_labels, target_names=classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "show_metrics(model, train_metrics, val_metrics, num_epochs,\"resnet50\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/FarahElshenawi/brain-tumor-classification/blob/main/Notebook/Brain_tumor_mri_Pytorch.ipynb\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "true_labels, predicted_labels, predicted_probs, misclassified_images = evaluate_model(model, val_loader, device, return_images=True)\n",
    "n_classes = predicted_probs.shape[1]  # Number of classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plot_results(true_labels, predicted_labels, predicted_probs, class_names)  # Evaluate and plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_misclassified_images(misclassified_images, true_labels, predicted_labels, 2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the following:\n",
    "# images: Tensor of shape [num_samples, channels, height, width]\n",
    "# true_labels: One-hot encoded or scalar labels\n",
    "# predicted_labels: Scalar predictions\n",
    "# n_classes: Number of classes in the dataset\n",
    "\n",
    "plot_correctly_predicted_images(misclassified_images, true_labels, predicted_labels, 2,5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
